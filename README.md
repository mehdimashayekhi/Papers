# Good-Papers/Talks, some of my recent readings/learnings

List of papers 

## Natural Language Understanding Related Papers

* [StarSpace: Embed All The Things!] (https://arxiv.org/pdf/1709.03856.pdf)
* [ConvS2S] (https://arxiv.org/abs/1705.03122)
* [Attention in general] (https://arxiv.org/pdf/1703.03906.pdf) (the link would help you quickly understand section 3.2)
*  Wavenet/Bytenet https://arxiv.org/abs/1609.03499 and https://arxiv.org/abs/1610.10099
*  Intra-attention: https://arxiv.org/pdf/1705.04304.pdf
* [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf) - Attention Is All You Need. <br />Presentation: https://www.youtube.com/watch?v=rBCqOTEfxvg. <br /> Code: https://github.com/tensorflow/tensor2tensor
* [Grammar as a Foreign Language](https://arxiv.org/pdf/1412.7449.pdf)
* [NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE](https://arxiv.org/pdf/1409.0473.pdf)
* [OUTRAGEOUSLY LARGE NEURAL NETWORKS: THE SPARSELY-GATED MIXTURE-OF-EXPERTS LAYER](https://arxiv.org/pdf/1701.06538.pdf)
* [Tensor2Tensor Presentation] (https://nlp.stanford.edu/seminar/details/lkaiser.pdf)
* [https://arxiv.org/pdf/1707.05589.pdf] ON THE STATE OF THE ART OF EVALUATION IN NEURAL LANGUAGE MODELS
* [https://www.youtube.com/user/neubig/videos] CMU CS 11-747, Neural Networks for NLP 

* [https://arxiv.org/pdf/1603.01354.pdf] End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF 

* [Summary of NIPS 2017 conference] https://cs.brown.edu/~dabel/blog/posts/misc/nips_2017.pdf

* [LEARNING DOCUMENT EMBEDDINGS BY PREDICTING N-GRAMS FOR SENTIMENT CLASSIFICATION OF LONG MOVIE REVIEWS] https://arxiv.org/pdf/1512.08183.pdf

* [One Model To Learn Them All] (https://arxiv.org/pdf/1706.05137.pdf)

* [EASY CONTEXTUAL INTENT PREDICTION AND SLOT DETECTION] (http://www.cs.toronto.edu/~aditya/publications/contextual.pdf)

* [Language Modeling with Gated Convolutional Networks, 2017] (https://arxiv.org/pdf/1612.08083.pdf)

* [End-to-End Memory Networks with Knowledge Carryover for Multi-Turn Spoken Language Understanding, 2017] (https://www.csie.ntu.edu.tw/%7Eyvchen/doc/IS16_ContextualSLU.pdf), https://github.com/yvchen/ContextualSLU

* [Named Entity Recognition with Bidirectional LSTM-CNNs (adding-lexicon-to-nlu), 2016] (https://arxiv.org/pdf/1511.08308v4.pdf)

* [Neural Belief Tracker: Data-Driven Dialogue State Tracking, 2017] (https://arxiv.org/pdf/1606.03777.pdf)

## Deep Reinforcement Learning/Chatbot

* [Reinforcement Learning: An Introduction, Richard S. Sutton] http://incompleteideas.net/book/bookdraft2017nov5.pdf
* [Deep RL Bootcamp, 26-27 August 2017, Berkeley CA] https://sites.google.com/view/deep-rl-bootcamp/lectures
* [Deep Reinforcement Learning for Dialogue Generation] https://arxiv.org/pdf/1606.01541.pdf
* [Adversarial Learning for Neural Dialogue Generation] https://arxiv.org/pdf/1701.06547.pdf
* [Deal or No Deal? End-to-End Learning for Negotiation Dialogues]https://arxiv.org/pdf/1706.05125.pdf,        [Presentation]https://nlp.stanford.edu/seminar/details/mlewis.pdf
* [CS 294: Deep Reinforcement Learning, Fall 2017] http://rll.berkeley.edu/deeprlcourse/
* https://yanpanlau.github.io/2016/07/10/FlappyBird-Keras.html
* https://leimao.github.io/article/Flappy-Bird-AI/
* [Pieter Abbeel delivers his keynote: Deep Learning for Robotics, at NIPS 2017.]https://www.facebook.com/nipsfoundation/videos/1554594181298482/
* Meta-Learning https://www.dropbox.com/s/a82gbu55k1k4diz/2017_12_xx_NIPS-HRL-workshop-final.pdf?dl=0




## Tensorflow Tutorials

* https://github.com/nlintz/TensorFlow-Tutorials
* https://github.com/pkmital/tensorflow_tutorials
* https://github.com/aymericdamien/TensorFlow-Examples



## Some interesting ML talks 

* [Ewa Dominowska - Generating a Billion Personal News Feeds - MLconf SEA 2016] https://www.youtube.com/watch?v=iXKR3HE-m8c
* [Rushin Shah, Engineering Manager, Facebook, NLP Related] https://www.youtube.com/watch?v=avViRGkdVKY



## Multi-Dimensional Recurrent Neural Networks

* [Multi-Dimensional Recurrent Neural Networks, 2013] https://arxiv.org/pdf/0705.2011.pdf
* [Generative Image Modeling Using Spatial LSTMs, 2015] https://arxiv.org/pdf/1506.03478.pdf
* [Pixel Recurrent Neural Networks, 2016] https://arxiv.org/pdf/1601.06759.pdf
* [Generative Models(GAN, PixelRNN,..., 2017)] (https://www.youtube.com/watch?v=5WoItGTWV54)
* [PIXELCNN++: IMPROVING THE PIXELCNN WITH DISCRETIZED LOGISTIC MIXTURE LIKELIHOOD AND OTHER MODIFICATIONS), 2017] (https://arxiv.org/pdf/1701.05517.pdf)


## Yes I GAN!

* [NIPS 2016 - Generative Adversarial Networks - Ian Goodfellow] https://www.youtube.com/watch?v=AJVyzd0rqdc, https://arxiv.org/pdf/1701.00160.pdf

* [Least Squares Generative Adversarial Networks, 2017] https://arxiv.org/pdf/1611.04076.pdf

* https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html

* https://towardsdatascience.com/gan-introduction-and-implementation-part1-implement-a-simple-gan-in-tf-for-mnist-handwritten-de00a759ae5c

* [UNSUPERVISED REPRESENTATION LEARNING WITH DEEP CONVOLUTIONAL GENERATIVE ADVERSARIAL NETWORKS, DCGAN, 2016] https://github.com/Newmu/dcgan_code, https://arxiv.org/pdf/1511.06434.pdf

* [InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets, 2016] https://arxiv.org/pdf/1606.03657.pdf






